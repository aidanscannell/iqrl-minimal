defaults:
  - base_vqddpg
_target_: src.agents.VectorQuantized_DDPG
# _convert_: all

mlp_dims: [256, 256]
exploration_noise: 0.2
policy_noise: 0.2
noise_clip: 0.5
learning_rate: 3e-4
batch_size: 512
num_updates: 1000 # 1000 is 1 update per new data
# actor_update_freq: 2  # update actor less frequently than critic
# nstep: 3
gamma: 0.99
tau: 0.005
device: ${device}
name: "VQ-DDPG"

vq_learning_rate: 3e-4
vq_batch_size: 256
vq_num_updates: 5000
# vq_num_updates: 1000
# levels: [8, 6, 5]  # target size 2^8, actual size 240
levels: [8, 6, 5]  # target size 2^8, actual size 240
# levels: [8]  # target size 2^8, actual size 240

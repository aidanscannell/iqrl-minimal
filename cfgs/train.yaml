defaults:
  # - train_config
  - agent: iqrl
  # - override hydra/launcher: slurm # Use slurm (on cluster) for multirun
  - override hydra/launcher: lumi_12hrs # Use slurm (on cluster) for multirun
  - override hydra/job_logging: colorlog
  # - override hydra/hydra_logging: hydra_debug
  - override hydra/hydra_logging: colorlog
  - _self_

env_id: "cartpole"
dmc_task: "swingup"

# Experiment
train_validation_split: 0.7 # Fraction of data to use for training
max_episode_steps: 1000 # Max episode length
num_episodes: 500 # Number of training episodes
random_episodes: 10 # Number of random episodes at start
action_repeat: 2
buffer_size: 1e7
seed: 42
device: "cuda"  # "cpu" or "cuda" etc

# Evaluation
eval_every_episodes: 5
num_eval_episodes: 10
capture_eval_video: True # Fails on AMD GPU so set to False
capture_train_video: False

# W&B config
use_wandb: True
wandb_project_name: "lifelong-td3-tc"
monitor_gym: True
run_name: ${agent.name}__${seed}__${now:%Y-%m-%d_%H-%M-%S}

hydra:
  verbose: true
  run:
    dir: output/hydra/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: true
  sweep:
    dir: ${hydra.run.dir}
    subdir: ${hydra.job.num}
